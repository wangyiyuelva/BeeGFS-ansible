2024-04-20 16:28:49.315908: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-04-20 16:28:49.558373: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-04-20 16:28:49.597250: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /beegfs/virtualenv/venv/lib64/python3.9/site-packages/cv2/../../lib64:
2024-04-20 16:28:49.597881: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-04-20 16:28:49.635079: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-04-20 16:28:52.431488: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /beegfs/virtualenv/venv/lib64/python3.9/site-packages/cv2/../../lib64:
2024-04-20 16:28:52.432461: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /beegfs/virtualenv/venv/lib64/python3.9/site-packages/cv2/../../lib64:
2024-04-20 16:28:52.432979: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Pika version 1.3.2 connecting to ('10.0.0.108', 5673)
Pika version 1.3.2 connecting to ('10.0.0.108', 5673)
Socket connected: <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.5.211', 53422), raddr=('10.0.0.108', 5673)>
Socket connected: <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.5.211', 53422), raddr=('10.0.0.108', 5673)>
Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f06d3debfa0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f06d3debfa0> params=<ConnectionParameters host=10.0.0.108 port=5673 virtual_host=/ ssl=False>>).
Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f06d3debfa0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f06d3debfa0> params=<ConnectionParameters host=10.0.0.108 port=5673 virtual_host=/ ssl=False>>).
AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f06d3debfa0> params=<ConnectionParameters host=10.0.0.108 port=5673 virtual_host=/ ssl=False>>
AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f06d3debfa0> params=<ConnectionParameters host=10.0.0.108 port=5673 virtual_host=/ ssl=False>>
AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f06d3debfa0> params=<ConnectionParameters host=10.0.0.108 port=5673 virtual_host=/ ssl=False>>
AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f06d3debfa0> params=<ConnectionParameters host=10.0.0.108 port=5673 virtual_host=/ ssl=False>>
Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f06d3debfa0> params=<ConnectionParameters host=10.0.0.108 port=5673 virtual_host=/ ssl=False>>
Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f06d3debfa0> params=<ConnectionParameters host=10.0.0.108 port=5673 virtual_host=/ ssl=False>>
Created channel=1
Created channel=1
2024-04-20 16:29:20.149806: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-04-20 16:29:20.392114: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-04-20 16:29:20.429670: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /beegfs/virtualenv/venv/lib64/python3.9/site-packages/cv2/../../lib64:
2024-04-20 16:29:20.430316: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-04-20 16:29:20.466965: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-04-20 16:29:23.295537: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /beegfs/virtualenv/venv/lib64/python3.9/site-packages/cv2/../../lib64:
2024-04-20 16:29:23.296603: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /beegfs/virtualenv/venv/lib64/python3.9/site-packages/cv2/../../lib64:
2024-04-20 16:29:23.297099: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Fusing layers... 
Fusing layers... 
Model summary: 733 layers, 140054656 parameters, 0 gradients, 208.8 GFLOPs
Model summary: 733 layers, 140054656 parameters, 0 gradients, 208.8 GFLOPs
Loading DLC 2.3.9...
DLC loaded in light mode; you cannot use any GUI (labeling, relabeling and standalone GUI)
Your Computer IP Address is:10.0.5.211
 [*] Waiting for messages. To exit press CTRL+C
 [x] Received filename b'/beegfs/data/input/AAACXZTV.mp4'
 [x] Processing /beegfs/data/input/AAACXZTV.mp4
  0%|          | 0/33 [00:00<?, ?it/s]Pika version 1.3.2 connecting to ('10.0.0.108', 5673)
Pika version 1.3.2 connecting to ('10.0.0.108', 5673)
Socket connected: <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.25', 59714), raddr=('10.0.0.108', 5673)>
Socket connected: <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.25', 59714), raddr=('10.0.0.108', 5673)>
Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f804386af10>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f804386af10> params=<ConnectionParameters host=10.0.0.108 port=5673 virtual_host=/ ssl=False>>).
Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f804386af10>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f804386af10> params=<ConnectionParameters host=10.0.0.108 port=5673 virtual_host=/ ssl=False>>).
AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f804386af10> params=<ConnectionParameters host=10.0.0.108 port=5673 virtual_host=/ ssl=False>>
AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f804386af10> params=<ConnectionParameters host=10.0.0.108 port=5673 virtual_host=/ ssl=False>>
AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f804386af10> params=<ConnectionParameters host=10.0.0.108 port=5673 virtual_host=/ ssl=False>>
AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f804386af10> params=<ConnectionParameters host=10.0.0.108 port=5673 virtual_host=/ ssl=False>>
Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f804386af10> params=<ConnectionParameters host=10.0.0.108 port=5673 virtual_host=/ ssl=False>>
Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f804386af10> params=<ConnectionParameters host=10.0.0.108 port=5673 virtual_host=/ ssl=False>>
Created channel=1
Created channel=1
  3%|▎         | 1/33 [00:06<03:33,  6.68s/it]  6%|▌         | 2/33 [00:13<03:25,  6.62s/it]  9%|▉         | 3/33 [00:19<03:17,  6.60s/it] 12%|█▏        | 4/33 [00:26<03:11,  6.61s/it] 15%|█▌        | 5/33 [00:33<03:05,  6.61s/it] 18%|█▊        | 6/33 [00:39<02:58,  6.62s/it] 21%|██        | 7/33 [00:46<02:52,  6.63s/it] 24%|██▍       | 8/33 [00:53<02:46,  6.64s/it] 27%|██▋       | 9/33 [00:59<02:39,  6.65s/it] 30%|███       | 10/33 [01:06<02:32,  6.65s/it] 33%|███▎      | 11/33 [01:12<02:26,  6.64s/it] 36%|███▋      | 12/33 [01:19<02:19,  6.64s/it] 39%|███▉      | 13/33 [01:26<02:12,  6.63s/it] 42%|████▏     | 14/33 [01:32<02:06,  6.65s/it] 45%|████▌     | 15/33 [01:39<01:59,  6.66s/it]Fusing layers... 
Fusing layers... 
Model summary: 733 layers, 140054656 parameters, 0 gradients, 208.8 GFLOPs
Model summary: 733 layers, 140054656 parameters, 0 gradients, 208.8 GFLOPs
Loading DLC 2.3.9...
DLC loaded in light mode; you cannot use any GUI (labeling, relabeling and standalone GUI)
Your Computer IP Address is:10.0.2.25
 [*] Waiting for messages. To exit press CTRL+C
 [x] Received filename b'/beegfs/data/input/AAAUILHH.mp4'
 [x] Processing /beegfs/data/input/AAAUILHH.mp4
  0%|          | 0/57 [00:00<?, ?it/s]  2%|▏         | 1/57 [00:06<06:15,  6.71s/it]  4%|▎         | 2/57 [00:13<06:04,  6.62s/it]  5%|▌         | 3/57 [00:19<05:59,  6.65s/it]  7%|▋         | 4/57 [00:26<05:52,  6.65s/it]2024-04-20 16:31:54.004666: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-04-20 16:31:54.255267: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-04-20 16:31:54.298019: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /beegfs/virtualenv/venv/lib64/python3.9/site-packages/cv2/../../lib64:
2024-04-20 16:31:54.298742: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-04-20 16:31:54.339053: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-04-20 16:31:57.340619: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /beegfs/virtualenv/venv/lib64/python3.9/site-packages/cv2/../../lib64:
2024-04-20 16:31:57.341727: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /beegfs/virtualenv/venv/lib64/python3.9/site-packages/cv2/../../lib64:
2024-04-20 16:31:57.342811: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Pika version 1.3.2 connecting to ('10.0.0.108', 5673)
Pika version 1.3.2 connecting to ('10.0.0.108', 5673)
Socket connected: <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.25', 53936), raddr=('10.0.0.108', 5673)>
Socket connected: <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.2.25', 53936), raddr=('10.0.0.108', 5673)>
Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f67d784df10>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f67d784df10> params=<ConnectionParameters host=10.0.0.108 port=5673 virtual_host=/ ssl=False>>).
Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f67d784df10>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f67d784df10> params=<ConnectionParameters host=10.0.0.108 port=5673 virtual_host=/ ssl=False>>).
AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f67d784df10> params=<ConnectionParameters host=10.0.0.108 port=5673 virtual_host=/ ssl=False>>
AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f67d784df10> params=<ConnectionParameters host=10.0.0.108 port=5673 virtual_host=/ ssl=False>>
AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f67d784df10> params=<ConnectionParameters host=10.0.0.108 port=5673 virtual_host=/ ssl=False>>
AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f67d784df10> params=<ConnectionParameters host=10.0.0.108 port=5673 virtual_host=/ ssl=False>>
Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f67d784df10> params=<ConnectionParameters host=10.0.0.108 port=5673 virtual_host=/ ssl=False>>
Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f67d784df10> params=<ConnectionParameters host=10.0.0.108 port=5673 virtual_host=/ ssl=False>>
Created channel=1
Created channel=1
2024-04-20 16:32:19.118368: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-04-20 16:32:19.371204: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-04-20 16:32:19.409782: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /beegfs/virtualenv/venv/lib64/python3.9/site-packages/cv2/../../lib64:
2024-04-20 16:32:19.410474: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-04-20 16:32:19.447181: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-04-20 16:32:21.930347: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /beegfs/virtualenv/venv/lib64/python3.9/site-packages/cv2/../../lib64:
2024-04-20 16:32:21.931201: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /beegfs/virtualenv/venv/lib64/python3.9/site-packages/cv2/../../lib64:
2024-04-20 16:32:21.931734: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Pika version 1.3.2 connecting to ('10.0.0.108', 5673)
Pika version 1.3.2 connecting to ('10.0.0.108', 5673)
Socket connected: <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.5.211', 37710), raddr=('10.0.0.108', 5673)>
Socket connected: <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.5.211', 37710), raddr=('10.0.0.108', 5673)>
Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fba09a79fa0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fba09a79fa0> params=<ConnectionParameters host=10.0.0.108 port=5673 virtual_host=/ ssl=False>>).
Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fba09a79fa0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fba09a79fa0> params=<ConnectionParameters host=10.0.0.108 port=5673 virtual_host=/ ssl=False>>).
AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fba09a79fa0> params=<ConnectionParameters host=10.0.0.108 port=5673 virtual_host=/ ssl=False>>
AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fba09a79fa0> params=<ConnectionParameters host=10.0.0.108 port=5673 virtual_host=/ ssl=False>>
AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fba09a79fa0> params=<ConnectionParameters host=10.0.0.108 port=5673 virtual_host=/ ssl=False>>
AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fba09a79fa0> params=<ConnectionParameters host=10.0.0.108 port=5673 virtual_host=/ ssl=False>>
Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fba09a79fa0> params=<ConnectionParameters host=10.0.0.108 port=5673 virtual_host=/ ssl=False>>
Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fba09a79fa0> params=<ConnectionParameters host=10.0.0.108 port=5673 virtual_host=/ ssl=False>>
Created channel=1
Created channel=1
Fusing layers... 
Fusing layers... 
Fusing layers... 
Fusing layers... 
Model summary: 733 layers, 140054656 parameters, 0 gradients, 208.8 GFLOPs
Model summary: 733 layers, 140054656 parameters, 0 gradients, 208.8 GFLOPs
Model summary: 733 layers, 140054656 parameters, 0 gradients, 208.8 GFLOPs
Model summary: 733 layers, 140054656 parameters, 0 gradients, 208.8 GFLOPs
Loading DLC 2.3.9...
DLC loaded in light mode; you cannot use any GUI (labeling, relabeling and standalone GUI)
Your Computer IP Address is:10.0.5.211
 [*] Waiting for messages. To exit press CTRL+C
 [x] Received filename b'/beegfs/data/input/AAAUILHH.mp4'
 [x] Processing /beegfs/data/input/AAAUILHH.mp4
  0%|          | 0/57 [00:00<?, ?it/s]Loading DLC 2.3.9...
DLC loaded in light mode; you cannot use any GUI (labeling, relabeling and standalone GUI)
Your Computer IP Address is:10.0.2.25
 [*] Waiting for messages. To exit press CTRL+C
 [x] Received filename b'/beegfs/data/input/AAACXZTV.mp4'
 [x] Processing /beegfs/data/input/AAACXZTV.mp4
  0%|          | 0/33 [00:00<?, ?it/s]  2%|▏         | 1/57 [00:06<06:10,  6.61s/it]  3%|▎         | 1/33 [00:06<03:37,  6.81s/it]  4%|▎         | 2/57 [00:13<06:09,  6.72s/it]  6%|▌         | 2/33 [00:13<03:30,  6.78s/it]  5%|▌         | 3/57 [00:20<06:04,  6.75s/it]  9%|▉         | 3/33 [00:20<03:22,  6.75s/it]  7%|▋         | 4/57 [00:26<05:58,  6.76s/it] 12%|█▏        | 4/33 [00:27<03:16,  6.78s/it]  9%|▉         | 5/57 [00:33<05:51,  6.76s/it] 15%|█▌        | 5/33 [00:33<03:10,  6.80s/it] 11%|█         | 6/57 [00:40<05:44,  6.76s/it] 18%|█▊        | 6/33 [00:40<03:03,  6.81s/it] 12%|█▏        | 7/57 [00:47<05:36,  6.73s/it] 21%|██        | 7/33 [00:47<02:57,  6.83s/it] 14%|█▍        | 8/57 [00:53<05:28,  6.71s/it] 24%|██▍       | 8/33 [00:54<02:50,  6.83s/it] 16%|█▌        | 9/57 [01:00<05:21,  6.69s/it] 27%|██▋       | 9/33 [01:01<02:43,  6.83s/it] 18%|█▊        | 10/57 [01:07<05:14,  6.69s/it] 30%|███       | 10/33 [01:08<02:37,  6.83s/it] 19%|█▉        | 11/57 [01:13<05:07,  6.68s/it] 33%|███▎      | 11/33 [01:14<02:30,  6.84s/it] 21%|██        | 12/57 [01:20<05:02,  6.72s/it] 36%|███▋      | 12/33 [01:21<02:23,  6.84s/it] 23%|██▎       | 13/57 [01:27<04:55,  6.71s/it] 39%|███▉      | 13/33 [01:28<02:16,  6.84s/it] 25%|██▍       | 14/57 [01:33<04:47,  6.69s/it] 42%|████▏     | 14/33 [01:35<02:09,  6.84s/it] 26%|██▋       | 15/57 [01:40<04:40,  6.67s/it] 45%|████▌     | 15/33 [01:42<02:03,  6.83s/it] 28%|██▊       | 16/57 [01:47<04:33,  6.68s/it] 48%|████▊     | 16/33 [01:49<01:56,  6.83s/it] 30%|██▉       | 17/57 [01:53<04:26,  6.67s/it] 52%|█████▏    | 17/33 [01:55<01:49,  6.83s/it] 32%|███▏      | 18/57 [02:00<04:20,  6.67s/it] 55%|█████▍    | 18/33 [02:02<01:42,  6.83s/it] 33%|███▎      | 19/57 [02:07<04:13,  6.67s/it] 58%|█████▊    | 19/33 [02:09<01:35,  6.83s/it] 35%|███▌      | 20/57 [02:14<04:08,  6.71s/it] 61%|██████    | 20/33 [02:16<01:28,  6.83s/it] 37%|███▋      | 21/57 [02:20<04:01,  6.71s/it] 64%|██████▎   | 21/33 [02:23<01:22,  6.84s/it] 39%|███▊      | 22/57 [02:27<03:54,  6.71s/it] 67%|██████▋   | 22/33 [02:30<01:15,  6.85s/it] 40%|████      | 23/57 [02:34<03:47,  6.70s/it] 70%|██████▉   | 23/33 [02:37<01:08,  6.85s/it] 42%|████▏     | 24/57 [02:40<03:41,  6.70s/it] 73%|███████▎  | 24/33 [02:43<01:01,  6.85s/it] 44%|████▍     | 25/57 [02:47<03:34,  6.70s/it] 76%|███████▌  | 25/33 [02:50<00:54,  6.85s/it] 46%|████▌     | 26/57 [02:54<03:27,  6.70s/it] 79%|███████▉  | 26/33 [02:57<00:47,  6.85s/it] 47%|████▋     | 27/57 [03:00<03:21,  6.70s/it] 82%|████████▏ | 27/33 [03:04<00:41,  6.84s/it] 49%|████▉     | 28/57 [03:07<03:15,  6.73s/it] 85%|████████▍ | 28/33 [03:11<00:34,  6.83s/it] 51%|█████     | 29/57 [03:14<03:09,  6.77s/it] 88%|████████▊ | 29/33 [03:18<00:27,  6.83s/it] 53%|█████▎    | 30/57 [03:21<03:02,  6.77s/it] 91%|█████████ | 30/33 [03:24<00:20,  6.82s/it] 54%|█████▍    | 31/57 [03:28<02:56,  6.77s/it] 94%|█████████▍| 31/33 [03:31<00:13,  6.81s/it] 56%|█████▌    | 32/57 [03:34<02:49,  6.78s/it] 97%|█████████▋| 32/33 [03:38<00:06,  6.81s/it] 58%|█████▊    | 33/57 [03:41<02:42,  6.75s/it]100%|██████████| 33/33 [03:45<00:00,  6.80s/it] 60%|█████▉    | 34/57 [03:48<02:35,  6.77s/it]34it [03:52,  6.80s/it]                        34it [03:52,  6.82s/it]
Config:
{'all_joints': [[0],
                [1],
                [2],
                [3],
                [4],
                [5],
                [6],
                [7],
                [8],
                [9],
                [10],
                [11],
                [12],
                [13],
                [14],
                [15],
                [16],
                [17],
                [18],
                [19],
                [20],
                [21],
                [22],
                [23],
                [24],
                [25],
                [26],
                [27],
                [28],
                [29],
                [30],
                [31],
                [32],
                [33],
                [34],
                [35],
                [36],
                [37],
                [38]],
 'all_joints_names': ['nose',
                      'upper_jaw',
                      'lower_jaw',
                      'mouth_end_right',
                      'mouth_end_left',
                      'right_eye',
                      'right_earbase',
                      'right_earend',
                      'right_antler_base',
                      'right_antler_end',
                      'left_eye',
                      'left_earbase',
                      'left_earend',
                      'left_antler_base',
                      'left_antler_end',
                      'neck_base',
                      'neck_end',
                      'throat_base',
                      'throat_end',
                      'back_base',
                      'back_end',
                      'back_middle',
                      'tail_base',
                      'tail_end',
                      'front_left_thai',
                      'front_left_knee',
                      'front_left_paw',
                      'front_right_thai',
                      'front_right_knee',
                      'front_right_paw',
                      'back_left_paw',
                      'back_left_thai',
                      'back_right_thai',
                      'back_left_knee',
                      'back_right_knee',
                      'back_right_paw',
                      'belly_bottom',
                      'body_middle_right',
                      'body_middle_left'],
 'alpha_r': 0.02,
 'apply_prob': 0.5,
 'batch_size': 1,
 'clahe': True,
 'claheratio': 0.1,
 'crop_pad': 0,
 'crop_sampling': 'hybrid',
 'crop_size': [400, 400],
 'cropratio': 0.4,
 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_ma_superquadrupedMarch30/ma_superquadruped_maDLC_scorer85shuffle1.pickle',
 'dataset_type': 'multi-animal-imgaug',
 'decay_steps': 30000,
 'deterministic': False,
 'display_iters': 500,
 'edge': False,
 'emboss': {'alpha': [0.0, 1.0], 'embossratio': 0.1, 'strength': [0.5, 1.5]},
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'gradient_masking': True,
 'histeq': True,
 'histeqratio': 0.1,
 'init_weights': None,
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'lr_init': 0.0005,
 'max_input_size': 1500,
 'max_shift': 0.4,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_ma_superquadrupedMarch30/Documentation_data-ma_superquadruped_85shuffle1.pickle',
 'min_input_size': 64,
 'mirror': False,
 'multi_stage': True,
 'multi_step': [[0.0001, 7500], [5e-05, 12000], [1e-05, 1000000]],
 'net_type': 'resnet_50',
 'num_idchannel': 0,
 'num_joints': 39,
 'num_limbs': 741,
 'optimizer': 'adam',
 'pafwidth': 20,
 'pairwise_huber_loss': False,
 'pairwise_loss_weight': 0.1,
 'pairwise_predict': False,
 'partaffinityfield_graph': [],
 'partaffinityfield_predict': False,
 'pos_dist_thresh': 17,
 'pre_resize': [],
 'project_path': None,
 'regularize': False,
 'rotation': 25,
 'rotratio': 0.4,
 'save_iters': 10000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'sharpen': False,
 'sharpenratio': 0.3,
 'shuffle': True,
 'snapshot_prefix': '/beegfs/virtualenv/venv/lib/python3.9/site-packages/deeplabcut/pose_estimation_tensorflow/superanimal_configs/superquadruped.yamlsnapshot',
 'stride': 8.0,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
Config:
{'all_joints': [[0],
                [1],
                [2],
                [3],
                [4],
                [5],
                [6],
                [7],
                [8],
                [9],
                [10],
                [11],
                [12],
                [13],
                [14],
                [15],
                [16],
                [17],
                [18],
                [19],
                [20],
                [21],
                [22],
                [23],
                [24],
                [25],
                [26],
                [27],
                [28],
                [29],
                [30],
                [31],
                [32],
                [33],
                [34],
                [35],
                [36],
                [37],
                [38]],
 'all_joints_names': ['nose',
                      'upper_jaw',
                      'lower_jaw',
                      'mouth_end_right',
                      'mouth_end_left',
                      'right_eye',
                      'right_earbase',
                      'right_earend',
                      'right_antler_base',
                      'right_antler_end',
                      'left_eye',
                      'left_earbase',
                      'left_earend',
                      'left_antler_base',
                      'left_antler_end',
                      'neck_base',
                      'neck_end',
                      'throat_base',
                      'throat_end',
                      'back_base',
                      'back_end',
                      'back_middle',
                      'tail_base',
                      'tail_end',
                      'front_left_thai',
                      'front_left_knee',
                      'front_left_paw',
                      'front_right_thai',
                      'front_right_knee',
                      'front_right_paw',
                      'back_left_paw',
                      'back_left_thai',
                      'back_right_thai',
                      'back_left_knee',
                      'back_right_knee',
                      'back_right_paw',
                      'belly_bottom',
                      'body_middle_right',
                      'body_middle_left'],
 'alpha_r': 0.02,
 'apply_prob': 0.5,
 'batch_size': 1,
 'clahe': True,
 'claheratio': 0.1,
 'crop_pad': 0,
 'crop_sampling': 'hybrid',
 'crop_size': [400, 400],
 'cropratio': 0.4,
 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_ma_superquadrupedMarch30/ma_superquadruped_maDLC_scorer85shuffle1.pickle',
 'dataset_type': 'multi-animal-imgaug',
 'decay_steps': 30000,
 'deterministic': False,
 'display_iters': 500,
 'edge': False,
 'emboss': {'alpha': [0.0, 1.0], 'embossratio': 0.1, 'strength': [0.5, 1.5]},
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'gradient_masking': True,
 'histeq': True,
 'histeqratio': 0.1,
 'init_weights': None,
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'lr_init': 0.0005,
 'max_input_size': 1500,
 'max_shift': 0.4,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_ma_superquadrupedMarch30/Documentation_data-ma_superquadruped_85shuffle1.pickle',
 'min_input_size': 64,
 'mirror': False,
 'multi_stage': True,
 'multi_step': [[0.0001, 7500], [5e-05, 12000], [1e-05, 1000000]],
 'net_type': 'resnet_50',
 'num_idchannel': 0,
 'num_joints': 39,
 'num_limbs': 741,
 'optimizer': 'adam',
 'pafwidth': 20,
 'pairwise_huber_loss': False,
 'pairwise_loss_weight': 0.1,
 'pairwise_predict': False,
 'partaffinityfield_graph': [],
 'partaffinityfield_predict': False,
 'pos_dist_thresh': 17,
 'pre_resize': [],
 'project_path': None,
 'regularize': False,
 'rotation': 25,
 'rotratio': 0.4,
 'save_iters': 10000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'sharpen': False,
 'sharpenratio': 0.3,
 'shuffle': True,
 'snapshot_prefix': '/beegfs/virtualenv/venv/lib/python3.9/site-packages/deeplabcut/pose_estimation_tensorflow/superanimal_configs/superquadruped.yamlsnapshot',
 'stride': 8.0,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
/beegfs/virtualenv/venv/lib64/python3.9/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  warnings.warn('`layer.apply` is deprecated and '
2024-04-20 16:37:57.792032: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /beegfs/virtualenv/venv/lib64/python3.9/site-packages/cv2/../../lib64:
2024-04-20 16:37:57.792697: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)
2024-04-20 16:37:57.793420: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-0-2-25.eu-west-2.compute.internal): /proc/driver/nvidia/version does not exist
2024-04-20 16:37:57.795066: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-04-20 16:37:57.816839: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled
/beegfs/virtualenv/venv/lib/python3.9/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/superanimal_quadruped_weights exists, using the downloaded weights
Loading  /beegfs/data/output/AAACXZTVwild.mp4
Duration of video [s]:  6.8 , recorded with  5.0 fps!
Overall # of frames:  34  found with (before cropping) frame dimensions:  640 360
Starting to extract posture
  0%|          | 0/34 [00:00<?, ?it/s] 61%|██████▏   | 35/57 [03:55<02:28,  6.77s/it]  3%|▎         | 1/34 [00:05<02:53,  5.27s/it] 63%|██████▎   | 36/57 [04:02<02:22,  6.77s/it]  6%|▌         | 2/34 [00:09<02:36,  4.90s/it] 65%|██████▍   | 37/57 [04:08<02:15,  6.76s/it]  9%|▉         | 3/34 [00:14<02:26,  4.73s/it] 12%|█▏        | 4/34 [00:18<02:19,  4.65s/it] 67%|██████▋   | 38/57 [04:15<02:07,  6.71s/it] 15%|█▍        | 5/34 [00:23<02:12,  4.57s/it] 68%|██████▊   | 39/57 [04:21<01:59,  6.65s/it] 18%|█▊        | 6/34 [00:27<02:06,  4.52s/it] 21%|██        | 7/34 [00:32<02:01,  4.49s/it] 70%|███████   | 40/57 [04:28<01:52,  6.60s/it] 24%|██▎       | 8/34 [00:36<01:56,  4.48s/it] 72%|███████▏  | 41/57 [04:34<01:45,  6.56s/it] 26%|██▋       | 9/34 [00:41<01:51,  4.46s/it] 29%|██▉       | 10/34 [00:45<01:46,  4.44s/it] 74%|███████▎  | 42/57 [04:41<01:38,  6.54s/it] 32%|███▏      | 11/34 [00:49<01:41,  4.43s/it] 75%|███████▌  | 43/57 [04:47<01:31,  6.52s/it] 35%|███▌      | 12/34 [00:54<01:37,  4.43s/it] 38%|███▊      | 13/34 [00:58<01:32,  4.43s/it] 77%|███████▋  | 44/57 [04:54<01:24,  6.52s/it] 41%|████      | 14/34 [01:03<01:28,  4.42s/it] 79%|███████▉  | 45/57 [05:00<01:18,  6.50s/it] 44%|████▍     | 15/34 [01:07<01:24,  4.42s/it] 81%|████████  | 46/57 [05:07<01:11,  6.49s/it] 47%|████▋     | 16/34 [01:12<01:19,  4.42s/it] 50%|█████     | 17/34 [01:16<01:15,  4.42s/it] 82%|████████▏ | 47/57 [05:13<01:04,  6.50s/it] 53%|█████▎    | 18/34 [01:20<01:10,  4.42s/it] 84%|████████▍ | 48/57 [05:20<00:58,  6.51s/it] 56%|█████▌    | 19/34 [01:25<01:06,  4.41s/it] 59%|█████▉    | 20/34 [01:29<01:01,  4.42s/it] 86%|████████▌ | 49/57 [05:26<00:52,  6.51s/it] 62%|██████▏   | 21/34 [01:34<00:57,  4.42s/it] 88%|████████▊ | 50/57 [05:33<00:45,  6.52s/it] 65%|██████▍   | 22/34 [01:38<00:53,  4.42s/it] 68%|██████▊   | 23/34 [01:42<00:48,  4.42s/it] 89%|████████▉ | 51/57 [05:39<00:39,  6.52s/it] 71%|███████   | 24/34 [01:47<00:44,  4.42s/it] 91%|█████████ | 52/57 [05:46<00:32,  6.51s/it] 74%|███████▎  | 25/34 [01:51<00:39,  4.41s/it] 76%|███████▋  | 26/34 [01:56<00:35,  4.42s/it] 93%|█████████▎| 53/57 [05:52<00:26,  6.51s/it] 79%|███████▉  | 27/34 [02:00<00:30,  4.42s/it] 95%|█████████▍| 54/57 [05:59<00:19,  6.51s/it] 82%|████████▏ | 28/34 [02:05<00:26,  4.42s/it] 85%|████████▌ | 29/34 [02:09<00:22,  4.42s/it] 96%|█████████▋| 55/57 [06:05<00:13,  6.51s/it] 88%|████████▊ | 30/34 [02:13<00:17,  4.42s/it] 98%|█████████▊| 56/57 [06:12<00:06,  6.52s/it] 91%|█████████ | 31/34 [02:18<00:13,  4.42s/it] 94%|█████████▍| 32/34 [02:22<00:08,  4.42s/it]100%|██████████| 57/57 [06:18<00:00,  6.52s/it]100%|██████████| 57/57 [06:18<00:00,  6.65s/it]
Config:
{'all_joints': [[0],
                [1],
                [2],
                [3],
                [4],
                [5],
                [6],
                [7],
                [8],
                [9],
                [10],
                [11],
                [12],
                [13],
                [14],
                [15],
                [16],
                [17],
                [18],
                [19],
                [20],
                [21],
                [22],
                [23],
                [24],
                [25],
                [26],
                [27],
                [28],
                [29],
                [30],
                [31],
                [32],
                [33],
                [34],
                [35],
                [36],
                [37],
                [38]],
 'all_joints_names': ['nose',
                      'upper_jaw',
                      'lower_jaw',
                      'mouth_end_right',
                      'mouth_end_left',
                      'right_eye',
                      'right_earbase',
                      'right_earend',
                      'right_antler_base',
                      'right_antler_end',
                      'left_eye',
                      'left_earbase',
                      'left_earend',
                      'left_antler_base',
                      'left_antler_end',
                      'neck_base',
                      'neck_end',
                      'throat_base',
                      'throat_end',
                      'back_base',
                      'back_end',
                      'back_middle',
                      'tail_base',
                      'tail_end',
                      'front_left_thai',
                      'front_left_knee',
                      'front_left_paw',
                      'front_right_thai',
                      'front_right_knee',
                      'front_right_paw',
                      'back_left_paw',
                      'back_left_thai',
                      'back_right_thai',
                      'back_left_knee',
                      'back_right_knee',
                      'back_right_paw',
                      'belly_bottom',
                      'body_middle_right',
                      'body_middle_left'],
 'alpha_r': 0.02,
 'apply_prob': 0.5,
 'batch_size': 1,
 'clahe': True,
 'claheratio': 0.1,
 'crop_pad': 0,
 'crop_sampling': 'hybrid',
 'crop_size': [400, 400],
 'cropratio': 0.4,
 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_ma_superquadrupedMarch30/ma_superquadruped_maDLC_scorer85shuffle1.pickle',
 'dataset_type': 'multi-animal-imgaug',
 'decay_steps': 30000,
 'deterministic': False,
 'display_iters': 500,
 'edge': False,
 'emboss': {'alpha': [0.0, 1.0], 'embossratio': 0.1, 'strength': [0.5, 1.5]},
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'gradient_masking': True,
 'histeq': True,
 'histeqratio': 0.1,
 'init_weights': None,
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'lr_init': 0.0005,
 'max_input_size': 1500,
 'max_shift': 0.4,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_ma_superquadrupedMarch30/Documentation_data-ma_superquadruped_85shuffle1.pickle',
 'min_input_size': 64,
 'mirror': False,
 'multi_stage': True,
 'multi_step': [[0.0001, 7500], [5e-05, 12000], [1e-05, 1000000]],
 'net_type': 'resnet_50',
 'num_idchannel': 0,
 'num_joints': 39,
 'num_limbs': 741,
 'optimizer': 'adam',
 'pafwidth': 20,
 'pairwise_huber_loss': False,
 'pairwise_loss_weight': 0.1,
 'pairwise_predict': False,
 'partaffinityfield_graph': [],
 'partaffinityfield_predict': False,
 'pos_dist_thresh': 17,
 'pre_resize': [],
 'project_path': None,
 'regularize': False,
 'rotation': 25,
 'rotratio': 0.4,
 'save_iters': 10000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'sharpen': False,
 'sharpenratio': 0.3,
 'shuffle': True,
 'snapshot_prefix': '/beegfs/virtualenv/venv/lib/python3.9/site-packages/deeplabcut/pose_estimation_tensorflow/superanimal_configs/superquadruped.yamlsnapshot',
 'stride': 8.0,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
Config:
{'all_joints': [[0],
                [1],
                [2],
                [3],
                [4],
                [5],
                [6],
                [7],
                [8],
                [9],
                [10],
                [11],
                [12],
                [13],
                [14],
                [15],
                [16],
                [17],
                [18],
                [19],
                [20],
                [21],
                [22],
                [23],
                [24],
                [25],
                [26],
                [27],
                [28],
                [29],
                [30],
                [31],
                [32],
                [33],
                [34],
                [35],
                [36],
                [37],
                [38]],
 'all_joints_names': ['nose',
                      'upper_jaw',
                      'lower_jaw',
                      'mouth_end_right',
                      'mouth_end_left',
                      'right_eye',
                      'right_earbase',
                      'right_earend',
                      'right_antler_base',
                      'right_antler_end',
                      'left_eye',
                      'left_earbase',
                      'left_earend',
                      'left_antler_base',
                      'left_antler_end',
                      'neck_base',
                      'neck_end',
                      'throat_base',
                      'throat_end',
                      'back_base',
                      'back_end',
                      'back_middle',
                      'tail_base',
                      'tail_end',
                      'front_left_thai',
                      'front_left_knee',
                      'front_left_paw',
                      'front_right_thai',
                      'front_right_knee',
                      'front_right_paw',
                      'back_left_paw',
                      'back_left_thai',
                      'back_right_thai',
                      'back_left_knee',
                      'back_right_knee',
                      'back_right_paw',
                      'belly_bottom',
                      'body_middle_right',
                      'body_middle_left'],
 'alpha_r': 0.02,
 'apply_prob': 0.5,
 'batch_size': 1,
 'clahe': True,
 'claheratio': 0.1,
 'crop_pad': 0,
 'crop_sampling': 'hybrid',
 'crop_size': [400, 400],
 'cropratio': 0.4,
 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_ma_superquadrupedMarch30/ma_superquadruped_maDLC_scorer85shuffle1.pickle',
 'dataset_type': 'multi-animal-imgaug',
 'decay_steps': 30000,
 'deterministic': False,
 'display_iters': 500,
 'edge': False,
 'emboss': {'alpha': [0.0, 1.0], 'embossratio': 0.1, 'strength': [0.5, 1.5]},
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'gradient_masking': True,
 'histeq': True,
 'histeqratio': 0.1,
 'init_weights': None,
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'lr_init': 0.0005,
 'max_input_size': 1500,
 'max_shift': 0.4,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_ma_superquadrupedMarch30/Documentation_data-ma_superquadruped_85shuffle1.pickle',
 'min_input_size': 64,
 'mirror': False,
 'multi_stage': True,
 'multi_step': [[0.0001, 7500], [5e-05, 12000], [1e-05, 1000000]],
 'net_type': 'resnet_50',
 'num_idchannel': 0,
 'num_joints': 39,
 'num_limbs': 741,
 'optimizer': 'adam',
 'pafwidth': 20,
 'pairwise_huber_loss': False,
 'pairwise_loss_weight': 0.1,
 'pairwise_predict': False,
 'partaffinityfield_graph': [],
 'partaffinityfield_predict': False,
 'pos_dist_thresh': 17,
 'pre_resize': [],
 'project_path': None,
 'regularize': False,
 'rotation': 25,
 'rotratio': 0.4,
 'save_iters': 10000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'sharpen': False,
 'sharpenratio': 0.3,
 'shuffle': True,
 'snapshot_prefix': '/beegfs/virtualenv/venv/lib/python3.9/site-packages/deeplabcut/pose_estimation_tensorflow/superanimal_configs/superquadruped.yamlsnapshot',
 'stride': 8.0,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
/beegfs/virtualenv/venv/lib64/python3.9/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.
  warnings.warn('`layer.apply` is deprecated and '
2024-04-20 16:40:24.467352: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /beegfs/virtualenv/venv/lib64/python3.9/site-packages/cv2/../../lib64:
2024-04-20 16:40:24.468294: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)
2024-04-20 16:40:24.469179: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-0-5-211.eu-west-2.compute.internal): /proc/driver/nvidia/version does not exist
2024-04-20 16:40:24.470848: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-04-20 16:40:24.492235: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled
/beegfs/virtualenv/venv/lib/python3.9/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/superanimal_quadruped_weights exists, using the downloaded weights
Loading  /beegfs/data/output/AAAUILHHwild.mp4
Duration of video [s]:  11.4 , recorded with  5.0 fps!
Overall # of frames:  57  found with (before cropping) frame dimensions:  640 360
Starting to extract posture
  0%|          | 0/57 [00:00<?, ?it/s] 97%|█████████▋| 33/34 [02:27<00:04,  4.42s/it]100%|██████████| 34/34 [02:31<00:00,  4.43s/it]100%|██████████| 34/34 [02:31<00:00,  4.46s/it]
  2%|▏         | 1/57 [00:05<04:46,  5.12s/it]  4%|▎         | 2/57 [00:10<04:44,  5.17s/it]Config:
{'all_joints': [[0],
                [1],
                [2],
                [3],
                [4],
                [5],
                [6],
                [7],
                [8],
                [9],
                [10],
                [11],
                [12],
                [13],
                [14],
                [15],
                [16],
                [17],
                [18],
                [19],
                [20],
                [21],
                [22],
                [23],
                [24],
                [25],
                [26],
                [27],
                [28],
                [29],
                [30],
                [31],
                [32],
                [33],
                [34],
                [35],
                [36],
                [37],
                [38]],
 'all_joints_names': ['nose',
                      'upper_jaw',
                      'lower_jaw',
                      'mouth_end_right',
                      'mouth_end_left',
                      'right_eye',
                      'right_earbase',
                      'right_earend',
                      'right_antler_base',
                      'right_antler_end',
                      'left_eye',
                      'left_earbase',
                      'left_earend',
                      'left_antler_base',
                      'left_antler_end',
                      'neck_base',
                      'neck_end',
                      'throat_base',
                      'throat_end',
                      'back_base',
                      'back_end',
                      'back_middle',
                      'tail_base',
                      'tail_end',
                      'front_left_thai',
                      'front_left_knee',
                      'front_left_paw',
                      'front_right_thai',
                      'front_right_knee',
                      'front_right_paw',
                      'back_left_paw',
                      'back_left_thai',
                      'back_right_thai',
                      'back_left_knee',
                      'back_right_knee',
                      'back_right_paw',
                      'belly_bottom',
                      'body_middle_right',
                      'body_middle_left'],
 'alpha_r': 0.02,
 'apply_prob': 0.5,
 'batch_size': 1,
 'clahe': True,
 'claheratio': 0.1,
 'crop_pad': 0,
 'crop_sampling': 'hybrid',
 'crop_size': [400, 400],
 'cropratio': 0.4,
 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_ma_superquadrupedMarch30/ma_superquadruped_maDLC_scorer85shuffle1.pickle',
 'dataset_type': 'multi-animal-imgaug',
 'decay_steps': 30000,
 'deterministic': False,
 'display_iters': 500,
 'edge': False,
 'emboss': {'alpha': [0.0, 1.0], 'embossratio': 0.1, 'strength': [0.5, 1.5]},
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'gradient_masking': True,
 'histeq': True,
 'histeqratio': 0.1,
 'init_weights': None,
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'lr_init': 0.0005,
 'max_input_size': 1500,
 'max_shift': 0.4,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_ma_superquadrupedMarch30/Documentation_data-ma_superquadruped_85shuffle1.pickle',
 'min_input_size': 64,
 'mirror': False,
 'multi_stage': True,
 'multi_step': [[0.0001, 7500], [5e-05, 12000], [1e-05, 1000000]],
 'net_type': 'resnet_50',
 'num_idchannel': 0,
 'num_joints': 39,
 'num_limbs': 741,
 'optimizer': 'adam',
 'pafwidth': 20,
 'pairwise_huber_loss': False,
 'pairwise_loss_weight': 0.1,
 'pairwise_predict': False,
 'partaffinityfield_graph': [],
 'partaffinityfield_predict': False,
 'pos_dist_thresh': 17,
 'pre_resize': [],
 'project_path': None,
 'regularize': False,
 'rotation': 25,
 'rotratio': 0.4,
 'save_iters': 10000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'sharpen': False,
 'sharpenratio': 0.3,
 'shuffle': True,
 'snapshot_prefix': '/beegfs/virtualenv/venv/lib/python3.9/site-packages/deeplabcut/pose_estimation_tensorflow/superanimal_configs/superquadruped.yamlsnapshot',
 'stride': 8.0,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
Config:
{'all_joints': [[0],
                [1],
                [2],
                [3],
                [4],
                [5],
                [6],
                [7],
                [8],
                [9],
                [10],
                [11],
                [12],
                [13],
                [14],
                [15],
                [16],
                [17],
                [18],
                [19],
                [20],
                [21],
                [22],
                [23],
                [24],
                [25],
                [26],
                [27],
                [28],
                [29],
                [30],
                [31],
                [32],
                [33],
                [34],
                [35],
                [36],
                [37],
                [38]],
 'all_joints_names': ['nose',
                      'upper_jaw',
                      'lower_jaw',
                      'mouth_end_right',
                      'mouth_end_left',
                      'right_eye',
                      'right_earbase',
                      'right_earend',
                      'right_antler_base',
                      'right_antler_end',
                      'left_eye',
                      'left_earbase',
                      'left_earend',
                      'left_antler_base',
                      'left_antler_end',
                      'neck_base',
                      'neck_end',
                      'throat_base',
                      'throat_end',
                      'back_base',
                      'back_end',
                      'back_middle',
                      'tail_base',
                      'tail_end',
                      'front_left_thai',
                      'front_left_knee',
                      'front_left_paw',
                      'front_right_thai',
                      'front_right_knee',
                      'front_right_paw',
                      'back_left_paw',
                      'back_left_thai',
                      'back_right_thai',
                      'back_left_knee',
                      'back_right_knee',
                      'back_right_paw',
                      'belly_bottom',
                      'body_middle_right',
                      'body_middle_left'],
 'alpha_r': 0.02,
 'apply_prob': 0.5,
 'batch_size': 1,
 'clahe': True,
 'claheratio': 0.1,
 'crop_pad': 0,
 'crop_sampling': 'hybrid',
 'crop_size': [400, 400],
 'cropratio': 0.4,
 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_ma_superquadrupedMarch30/ma_superquadruped_maDLC_scorer85shuffle1.pickle',
 'dataset_type': 'multi-animal-imgaug',
 'decay_steps': 30000,
 'deterministic': False,
 'display_iters': 500,
 'edge': False,
 'emboss': {'alpha': [0.0, 1.0], 'embossratio': 0.1, 'strength': [0.5, 1.5]},
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'gradient_masking': True,
 'histeq': True,
 'histeqratio': 0.1,
 'init_weights': None,
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'lr_init': 0.0005,
 'max_input_size': 1500,
 'max_shift': 0.4,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_ma_superquadrupedMarch30/Documentation_data-ma_superquadruped_85shuffle1.pickle',
 'min_input_size': 64,
 'mirror': False,
 'multi_stage': True,
 'multi_step': [[0.0001, 7500], [5e-05, 12000], [1e-05, 1000000]],
 'net_type': 'resnet_50',
 'num_idchannel': 0,
 'num_joints': 39,
 'num_limbs': 741,
 'optimizer': 'adam',
 'pafwidth': 20,
 'pairwise_huber_loss': False,
 'pairwise_loss_weight': 0.1,
 'pairwise_predict': False,
 'partaffinityfield_graph': [],
 'partaffinityfield_predict': False,
 'pos_dist_thresh': 17,
 'pre_resize': [],
 'project_path': None,
 'regularize': False,
 'rotation': 25,
 'rotratio': 0.4,
 'save_iters': 10000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'sharpen': False,
 'sharpenratio': 0.3,
 'shuffle': True,
 'snapshot_prefix': '/beegfs/virtualenv/venv/lib/python3.9/site-packages/deeplabcut/pose_estimation_tensorflow/superanimal_configs/superquadruped.yamlsnapshot',
 'stride': 8.0,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
scale list range(200, 600, 50)
Saving results in /beegfs/data/output...
Starting to process video: /beegfs/data/output/AAACXZTVwild.mp4
Loading /beegfs/data/output/AAACXZTVwild.mp4 and data.
Duration of video [s]: 6.8, recorded with 5.0 fps!
Overall # of frames: 34 with cropped frame dimensions: 640 360
Generating frames and creating video.
  0%|          | 0/34 [00:00<?, ?it/s]100%|██████████| 34/34 [00:00<00:00, 374.79it/s]
  5%|▌         | 3/57 [00:14<04:21,  4.83s/it]  7%|▋         | 4/57 [00:19<04:07,  4.67s/it]  9%|▉         | 5/57 [00:23<03:55,  4.53s/it] 11%|█         | 6/57 [00:27<03:46,  4.45s/it] 12%|█▏        | 7/57 [00:32<03:39,  4.39s/it] 14%|█▍        | 8/57 [00:36<03:33,  4.36s/it] 16%|█▌        | 9/57 [00:40<03:28,  4.34s/it] 18%|█▊        | 10/57 [00:44<03:23,  4.33s/it] 19%|█▉        | 11/57 [00:49<03:19,  4.33s/it] 21%|██        | 12/57 [00:53<03:14,  4.32s/it] 23%|██▎       | 13/57 [00:57<03:09,  4.31s/it] 25%|██▍       | 14/57 [01:02<03:05,  4.31s/it] 26%|██▋       | 15/57 [01:06<03:01,  4.33s/it] 28%|██▊       | 16/57 [01:10<02:57,  4.33s/it] 30%|██▉       | 17/57 [01:15<02:52,  4.32s/it] 32%|███▏      | 18/57 [01:19<02:48,  4.31s/it] 33%|███▎      | 19/57 [01:23<02:43,  4.31s/it] 35%|███▌      | 20/57 [01:28<02:39,  4.30s/it] 37%|███▋      | 21/57 [01:32<02:34,  4.30s/it] 39%|███▊      | 22/57 [01:36<02:30,  4.30s/it] 40%|████      | 23/57 [01:40<02:26,  4.29s/it] 42%|████▏     | 24/57 [01:45<02:21,  4.29s/it] 44%|████▍     | 25/57 [01:49<02:17,  4.29s/it] 46%|████▌     | 26/57 [01:53<02:12,  4.29s/it] 47%|████▋     | 27/57 [01:58<02:08,  4.29s/it] 49%|████▉     | 28/57 [02:02<02:04,  4.29s/it] 51%|█████     | 29/57 [02:06<02:00,  4.29s/it] 53%|█████▎    | 30/57 [02:10<01:55,  4.29s/it] 54%|█████▍    | 31/57 [02:15<01:51,  4.30s/it] 56%|█████▌    | 32/57 [02:19<01:47,  4.30s/it] 58%|█████▊    | 33/57 [02:23<01:43,  4.30s/it] 60%|█████▉    | 34/57 [02:28<01:38,  4.29s/it] 61%|██████▏   | 35/57 [02:32<01:34,  4.29s/it] 63%|██████▎   | 36/57 [02:36<01:30,  4.30s/it] 65%|██████▍   | 37/57 [02:41<01:25,  4.30s/it] 67%|██████▋   | 38/57 [02:45<01:21,  4.30s/it] 68%|██████▊   | 39/57 [02:49<01:17,  4.30s/it] 70%|███████   | 40/57 [02:53<01:12,  4.29s/it] 72%|███████▏  | 41/57 [02:58<01:08,  4.29s/it] 74%|███████▎  | 42/57 [03:02<01:04,  4.29s/it] 75%|███████▌  | 43/57 [03:06<01:00,  4.29s/it] 77%|███████▋  | 44/57 [03:11<00:55,  4.29s/it] 79%|███████▉  | 45/57 [03:15<00:51,  4.29s/it] 81%|████████  | 46/57 [03:19<00:47,  4.29s/it] 82%|████████▏ | 47/57 [03:23<00:42,  4.29s/it] 84%|████████▍ | 48/57 [03:28<00:38,  4.29s/it] 86%|████████▌ | 49/57 [03:32<00:34,  4.29s/it] 88%|████████▊ | 50/57 [03:36<00:30,  4.29s/it] 89%|████████▉ | 51/57 [03:41<00:25,  4.29s/it] 91%|█████████ | 52/57 [03:45<00:21,  4.29s/it] 93%|█████████▎| 53/57 [03:49<00:17,  4.29s/it] 95%|█████████▍| 54/57 [03:53<00:12,  4.29s/it] 96%|█████████▋| 55/57 [03:58<00:08,  4.29s/it] 98%|█████████▊| 56/57 [04:02<00:04,  4.29s/it]100%|██████████| 57/57 [04:06<00:00,  4.29s/it]100%|██████████| 57/57 [04:06<00:00,  4.33s/it]
Config:
{'all_joints': [[0],
                [1],
                [2],
                [3],
                [4],
                [5],
                [6],
                [7],
                [8],
                [9],
                [10],
                [11],
                [12],
                [13],
                [14],
                [15],
                [16],
                [17],
                [18],
                [19],
                [20],
                [21],
                [22],
                [23],
                [24],
                [25],
                [26],
                [27],
                [28],
                [29],
                [30],
                [31],
                [32],
                [33],
                [34],
                [35],
                [36],
                [37],
                [38]],
 'all_joints_names': ['nose',
                      'upper_jaw',
                      'lower_jaw',
                      'mouth_end_right',
                      'mouth_end_left',
                      'right_eye',
                      'right_earbase',
                      'right_earend',
                      'right_antler_base',
                      'right_antler_end',
                      'left_eye',
                      'left_earbase',
                      'left_earend',
                      'left_antler_base',
                      'left_antler_end',
                      'neck_base',
                      'neck_end',
                      'throat_base',
                      'throat_end',
                      'back_base',
                      'back_end',
                      'back_middle',
                      'tail_base',
                      'tail_end',
                      'front_left_thai',
                      'front_left_knee',
                      'front_left_paw',
                      'front_right_thai',
                      'front_right_knee',
                      'front_right_paw',
                      'back_left_paw',
                      'back_left_thai',
                      'back_right_thai',
                      'back_left_knee',
                      'back_right_knee',
                      'back_right_paw',
                      'belly_bottom',
                      'body_middle_right',
                      'body_middle_left'],
 'alpha_r': 0.02,
 'apply_prob': 0.5,
 'batch_size': 1,
 'clahe': True,
 'claheratio': 0.1,
 'crop_pad': 0,
 'crop_sampling': 'hybrid',
 'crop_size': [400, 400],
 'cropratio': 0.4,
 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_ma_superquadrupedMarch30/ma_superquadruped_maDLC_scorer85shuffle1.pickle',
 'dataset_type': 'multi-animal-imgaug',
 'decay_steps': 30000,
 'deterministic': False,
 'display_iters': 500,
 'edge': False,
 'emboss': {'alpha': [0.0, 1.0], 'embossratio': 0.1, 'strength': [0.5, 1.5]},
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'gradient_masking': True,
 'histeq': True,
 'histeqratio': 0.1,
 'init_weights': None,
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'lr_init': 0.0005,
 'max_input_size': 1500,
 'max_shift': 0.4,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_ma_superquadrupedMarch30/Documentation_data-ma_superquadruped_85shuffle1.pickle',
 'min_input_size': 64,
 'mirror': False,
 'multi_stage': True,
 'multi_step': [[0.0001, 7500], [5e-05, 12000], [1e-05, 1000000]],
 'net_type': 'resnet_50',
 'num_idchannel': 0,
 'num_joints': 39,
 'num_limbs': 741,
 'optimizer': 'adam',
 'pafwidth': 20,
 'pairwise_huber_loss': False,
 'pairwise_loss_weight': 0.1,
 'pairwise_predict': False,
 'partaffinityfield_graph': [],
 'partaffinityfield_predict': False,
 'pos_dist_thresh': 17,
 'pre_resize': [],
 'project_path': None,
 'regularize': False,
 'rotation': 25,
 'rotratio': 0.4,
 'save_iters': 10000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'sharpen': False,
 'sharpenratio': 0.3,
 'shuffle': True,
 'snapshot_prefix': '/beegfs/virtualenv/venv/lib/python3.9/site-packages/deeplabcut/pose_estimation_tensorflow/superanimal_configs/superquadruped.yamlsnapshot',
 'stride': 8.0,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
Config:
{'all_joints': [[0],
                [1],
                [2],
                [3],
                [4],
                [5],
                [6],
                [7],
                [8],
                [9],
                [10],
                [11],
                [12],
                [13],
                [14],
                [15],
                [16],
                [17],
                [18],
                [19],
                [20],
                [21],
                [22],
                [23],
                [24],
                [25],
                [26],
                [27],
                [28],
                [29],
                [30],
                [31],
                [32],
                [33],
                [34],
                [35],
                [36],
                [37],
                [38]],
 'all_joints_names': ['nose',
                      'upper_jaw',
                      'lower_jaw',
                      'mouth_end_right',
                      'mouth_end_left',
                      'right_eye',
                      'right_earbase',
                      'right_earend',
                      'right_antler_base',
                      'right_antler_end',
                      'left_eye',
                      'left_earbase',
                      'left_earend',
                      'left_antler_base',
                      'left_antler_end',
                      'neck_base',
                      'neck_end',
                      'throat_base',
                      'throat_end',
                      'back_base',
                      'back_end',
                      'back_middle',
                      'tail_base',
                      'tail_end',
                      'front_left_thai',
                      'front_left_knee',
                      'front_left_paw',
                      'front_right_thai',
                      'front_right_knee',
                      'front_right_paw',
                      'back_left_paw',
                      'back_left_thai',
                      'back_right_thai',
                      'back_left_knee',
                      'back_right_knee',
                      'back_right_paw',
                      'belly_bottom',
                      'body_middle_right',
                      'body_middle_left'],
 'alpha_r': 0.02,
 'apply_prob': 0.5,
 'batch_size': 1,
 'clahe': True,
 'claheratio': 0.1,
 'crop_pad': 0,
 'crop_sampling': 'hybrid',
 'crop_size': [400, 400],
 'cropratio': 0.4,
 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_ma_superquadrupedMarch30/ma_superquadruped_maDLC_scorer85shuffle1.pickle',
 'dataset_type': 'multi-animal-imgaug',
 'decay_steps': 30000,
 'deterministic': False,
 'display_iters': 500,
 'edge': False,
 'emboss': {'alpha': [0.0, 1.0], 'embossratio': 0.1, 'strength': [0.5, 1.5]},
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'gradient_masking': True,
 'histeq': True,
 'histeqratio': 0.1,
 'init_weights': None,
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'lr_init': 0.0005,
 'max_input_size': 1500,
 'max_shift': 0.4,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_ma_superquadrupedMarch30/Documentation_data-ma_superquadruped_85shuffle1.pickle',
 'min_input_size': 64,
 'mirror': False,
 'multi_stage': True,
 'multi_step': [[0.0001, 7500], [5e-05, 12000], [1e-05, 1000000]],
 'net_type': 'resnet_50',
 'num_idchannel': 0,
 'num_joints': 39,
 'num_limbs': 741,
 'optimizer': 'adam',
 'pafwidth': 20,
 'pairwise_huber_loss': False,
 'pairwise_loss_weight': 0.1,
 'pairwise_predict': False,
 'partaffinityfield_graph': [],
 'partaffinityfield_predict': False,
 'pos_dist_thresh': 17,
 'pre_resize': [],
 'project_path': None,
 'regularize': False,
 'rotation': 25,
 'rotratio': 0.4,
 'save_iters': 10000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'sharpen': False,
 'sharpenratio': 0.3,
 'shuffle': True,
 'snapshot_prefix': '/beegfs/virtualenv/venv/lib/python3.9/site-packages/deeplabcut/pose_estimation_tensorflow/superanimal_configs/superquadruped.yamlsnapshot',
 'stride': 8.0,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
scale list range(200, 600, 50)
Saving results in /beegfs/data/output...
Starting to process video: /beegfs/data/output/AAAUILHHwild.mp4
Loading /beegfs/data/output/AAAUILHHwild.mp4 and data.
Duration of video [s]: 11.4, recorded with 5.0 fps!
Overall # of frames: 57 with cropped frame dimensions: 640 360
Generating frames and creating video.
  0%|          | 0/57 [00:00<?, ?it/s] 54%|█████▍    | 31/57 [00:00<00:00, 302.18it/s]100%|██████████| 57/57 [00:00<00:00, 326.08it/s]
Fusing layers... 
Fusing layers... 
Fusing layers... 
Fusing layers... 
Model summary: 733 layers, 140054656 parameters, 0 gradients, 208.8 GFLOPs
Model summary: 733 layers, 140054656 parameters, 0 gradients, 208.8 GFLOPs
Model summary: 733 layers, 140054656 parameters, 0 gradients, 208.8 GFLOPs
Model summary: 733 layers, 140054656 parameters, 0 gradients, 208.8 GFLOPs
Successfully moved /beegfs/data/input/AAACXZTV.mp4 to /beegfs/data/input_done/AAACXZTV.mp4
 [x] Complete /beegfs/data/input/AAACXZTV.mp4
 [x] Received filename b'/beegfs/data/input/AAACXZTV.mp4'
 [x] Processing /beegfs/data/input/AAACXZTV.mp4
  0%|          | 0/33 [00:00<?, ?it/s]Successfully moved /beegfs/data/input/AAAUILHH.mp4 to /beegfs/data/input_done/AAAUILHH.mp4
 [x] Complete /beegfs/data/input/AAAUILHH.mp4
 [x] Received filename b'/beegfs/data/input/AAAUILHH.mp4'
 [x] Processing /beegfs/data/input/AAAUILHH.mp4
  0%|          | 0/57 [00:00<?, ?it/s]  2%|▏         | 1/57 [00:06<06:28,  6.93s/it]  3%|▎         | 1/33 [00:07<03:45,  7.03s/it]  4%|▎         | 2/57 [00:13<06:14,  6.80s/it]  6%|▌         | 2/33 [00:14<03:38,  7.03s/it]  5%|▌         | 3/57 [00:20<06:08,  6.82s/it]  9%|▉         | 3/33 [00:20<03:28,  6.96s/it]  7%|▋         | 4/57 [00:27<06:01,  6.81s/it] 12%|█▏        | 4/33 [00:27<03:22,  6.97s/it]  9%|▉         | 5/57 [00:34<05:54,  6.81s/it] 15%|█▌        | 5/33 [00:34<03:15,  6.98s/it] 11%|█         | 6/57 [00:40<05:48,  6.83s/it] 18%|█▊        | 6/33 [00:41<03:08,  6.99s/it] 12%|█▏        | 7/57 [00:47<05:39,  6.79s/it] 21%|██        | 7/33 [00:48<03:01,  6.99s/it] 14%|█▍        | 8/57 [00:54<05:31,  6.78s/it] 24%|██▍       | 8/33 [00:55<02:54,  7.00s/it] 16%|█▌        | 9/57 [01:01<05:24,  6.75s/it] 27%|██▋       | 9/33 [01:02<02:47,  6.99s/it] 18%|█▊        | 10/57 [01:07<05:17,  6.76s/it] 30%|███       | 10/33 [01:09<02:40,  7.00s/it] 19%|█▉        | 11/57 [01:14<05:10,  6.75s/it] 33%|███▎      | 11/33 [01:16<02:34,  7.00s/it] 21%|██        | 12/57 [01:21<05:05,  6.78s/it] 36%|███▋      | 12/33 [01:23<02:27,  7.01s/it] 23%|██▎       | 13/57 [01:28<04:57,  6.77s/it] 39%|███▉      | 13/33 [01:31<02:20,  7.04s/it] 25%|██▍       | 14/57 [01:34<04:50,  6.76s/it] 42%|████▏     | 14/33 [01:38<02:13,  7.03s/it] 26%|██▋       | 15/57 [01:41<04:42,  6.74s/it] 28%|██▊       | 16/57 [01:48<04:34,  6.69s/it]